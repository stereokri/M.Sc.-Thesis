<documents>
<document index='0'>
<source>https://python.langchain.com/docs/integrations/retrievers/sec_filings</source>
<doc_content>SEC filing | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# SEC filing

The SEC filing is a financial statement or other formal document submitted to the U.S. Securities and Exchange Commission (SEC). Public companies, certain insiders, and broker-dealers are required to make regular SEC filings. Investors and financial professionals rely on these filings for information about companies they are evaluating for investment purposes.

SEC filings data powered by [Kay.ai](https://kay.ai) and [Cybersyn](https://www.cybersyn.com/) via [Snowflake Marketplace](https://app.snowflake.com/marketplace/providers/GZTSZAS2KCS/Cybersyn%2C%20Inc).

## Setup‚Äã

First, you will need to install the `kay` package. You will also need an API key: you can get one for free at [https://kay.ai](https://kay.ai/). Once you have an API key, you must set it as an environment variable `KAY_API_KEY`.

In this example, we're going to use the `KayAiRetriever`. Take a look at the [kay notebook](/docs/integrations/retrievers/kay) for more detailed information for the parameters that it accepts.`

```python
# Setup API keys for Kay and OpenAI
from getpass import getpass

KAY_API_KEY = getpass()
OPENAI_API_KEY = getpass()
```

```text
     ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑
     ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑
```

```python
import os

os.environ["KAY_API_KEY"] = KAY_API_KEY
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
```

## Example‚Äã

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.retrievers import KayAiRetriever

model = ChatOpenAI(model_name="gpt-3.5-turbo")
retriever = KayAiRetriever.create(
    dataset_id="company", data_types=["10-K", "10-Q"], num_contexts=6
)
qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)
```

```python
questions = [
    "What are patterns in Nvidia's spend over the past three quarters?",
    # "What are some recent challenges faced by the renewable energy sector?",
]
chat_history = []

for question in questions:
    result = qa({"question": question, "chat_history": chat_history})
    chat_history.append((question, result["answer"]))
    print(f"-> **Question**: {question} \n")
    print(f"**Answer**: {result['answer']} \n")
```

```text
    -> **Question**: What are patterns in Nvidia's spend over the past three quarters? 
    
    **Answer**: Based on the provided information, here are the patterns in NVIDIA's spend over the past three quarters:
    
    1. Research and Development Expenses:
       - Q3 2022: Increased by 34% compared to Q3 2021.
       - Q1 2023: Increased by 40% compared to Q1 2022.
       - Q2 2022: Increased by 25% compared to Q2 2021.
       
       Overall, research and development expenses have been consistently increasing over the past three quarters.
    
    2. Sales, General and Administrative Expenses:
       - Q3 2022: Increased by 8% compared to Q3 2021.
       - Q1 2023: Increased by 14% compared to Q1 2022.
       - Q2 2022: Decreased by 16% compared to Q2 2021.
       
       The pattern for sales, general and administrative expenses is not as consistent, with some quarters showing an increase and others showing a decrease.
    
    3. Total Operating Expenses:
       - Q3 2022: Increased by 25% compared to Q3 2021.
       - Q1 2023: Increased by 113% compared to Q1 2022.
       - Q2 2022: Increased by 9% compared to Q2 2021.
       
       Total operating expenses have generally been increasing over the past three quarters, with a significant increase in Q1 2023.
    
    Overall, the pattern indicates a consistent increase in research and development expenses and total operating expenses, while sales, general and administrative expenses show some fluctuations. 
    
```

- [Setup](#setup)

- [Example](#example)</doc_content>
</document>





<document index='1'>
<source>https://python.langchain.com/docs/integrations/chat_loaders/gmail</source>
<doc_content>GMail | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# GMail

This loader goes over how to load data from GMail. There are many ways you could want to load data from GMail. This loader is currently fairly opinionated in how to do so. The way it does it is it first looks for all messages that you have sent. It then looks for messages where you are responding to a previous email. It then fetches that previous email, and creates a training example of that email, followed by your email.

Note that there are clear limitations here. For example, all examples created are only looking at the previous email for context.

To use:

- Set up a Google Developer Account: Go to the Google Developer Console, create a project, and enable the Gmail API for that project. This will give you a credentials.json file that you'll need later.

- Install the Google Client Library: Run the following command to install the Google Client Library:

```bash
pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client
```

```python
import os.path

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

SCOPES = ["https://www.googleapis.com/auth/gmail.readonly"]

creds = None
# The file token.json stores the user's access and refresh tokens, and is
# created automatically when the authorization flow completes for the first
# time.
if os.path.exists("email_token.json"):
    creds = Credentials.from_authorized_user_file("email_token.json", SCOPES)
# If there are no (valid) credentials available, let the user log in.
if not creds or not creds.valid:
    if creds and creds.expired and creds.refresh_token:
        creds.refresh(Request())
    else:
        flow = InstalledAppFlow.from_client_secrets_file(
            # your creds file here. Please create json file as here https://cloud.google.com/docs/authentication/getting-started
            "creds.json",
            SCOPES,
        )
        creds = flow.run_local_server(port=0)
    # Save the credentials for the next run
    with open("email_token.json", "w") as token:
        token.write(creds.to_json())
```

```python
from langchain.chat_loaders.gmail import GMailLoader
```

```python
loader = GMailLoader(creds=creds, n=3)
```

```python
data = loader.load()
```

```python
# Sometimes there can be errors which we silently ignore
len(data)
```

```text
    2
```

```python
from langchain.chat_loaders.utils import (
    map_ai_messages,
)
```

```python
# This makes messages sent by hchase@langchain.com the AI Messages
# This means you will train an LLM to predict as if it's responding as hchase
training_data = list(
    map_ai_messages(data, sender="Harrison Chase <hchase@langchain.com>")
)
```</doc_content>
</document>





<document index='2'>
<source>https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/</source>
<doc_content>Data anonymization with Microsoft Presidio | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Data anonymization with Microsoft Presidio

[](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/guides/privacy/presidio_data_anonymization/index.ipynb)

## Use case‚Äã

Data anonymization is crucial before passing information to a language model like GPT-4 because it helps protect privacy and maintain confidentiality. If data is not anonymized, sensitive information such as names, addresses, contact numbers, or other identifiers linked to specific individuals could potentially be learned and misused. Hence, by obscuring or removing this personally identifiable information (PII), data can be used freely without compromising individuals' privacy rights or breaching data protection laws and regulations.

## Overview‚Äã

Anonynization consists of two steps:

1. **Identification:** Identify all data fields that contain personally identifiable information (PII).

2. **Replacement**: Replace all PIIs with pseudo values or codes that do not reveal any personal information about the individual but can be used for reference. We're not using regular encryption, because the language model won't be able to understand the meaning or context of the encrypted data.

We use _Microsoft Presidio_ together with _Faker_ framework for anonymization purposes because of the wide range of functionalities they provide. The full implementation is available in `PresidioAnonymizer`.

## Quickstart‚Äã

Below you will find the use case on how to leverage anonymization in LangChain.

```python
# Install necessary packages
# ! pip install langchain langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker
# ! python -m spacy download en_core_web_lg
```

\
Let's see how PII anonymization works using a sample sentence:

```python
from langchain_experimental.data_anonymizer import PresidioAnonymizer

anonymizer = PresidioAnonymizer()

anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"
)
```

```text
    'My name is James Martinez, call me at (576)928-1972x679 or email me at lisa44@example.com'
```

### Using with LangChain Expression Language‚Äã

With LCEL we can easily chain together anonymization with the rest of our application.

```python
# Set env var OPENAI_API_KEY or load from a .env file:
# import dotenv

# dotenv.load_dotenv()
```

```python
text = """Slim Shady recently lost his wallet. 
Inside is some cash and his credit card with the number 4916 0387 9536 0861. 
If you would find it, please call at 313-666-7440 or write an email here: real.slim.shady@gmail.com."""
```

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts.prompt import PromptTemplate

anonymizer = PresidioAnonymizer()

template = """Rewrite this text into an official, short email:

{anonymized_text}"""
prompt = PromptTemplate.from_template(template)
llm = ChatOpenAI(temperature=0)

chain = {"anonymized_text": anonymizer.anonymize} | prompt | llm
response = chain.invoke(text)
print(response.content)
```

```text
    Dear Sir/Madam,
    
    We regret to inform you that Mr. Dennis Cooper has recently misplaced his wallet. The wallet contains a sum of cash and his credit card, bearing the number 3588895295514977. 
    
    Should you happen to come across the aforementioned wallet, kindly contact us immediately at (428)451-3494x4110 or send an email to perryluke@example.com.
    
    Your prompt assistance in this matter would be greatly appreciated.
    
    Yours faithfully,
    
    [Your Name]
```

## Customization‚Äã

We can specify `analyzed_fields` to only anonymize particular types of data.

```python
anonymizer = PresidioAnonymizer(analyzed_fields=["PERSON"])

anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"
)
```

```text
    'My name is Shannon Steele, call me at 313-666-7440 or email me at real.slim.shady@gmail.com'
```

As can be observed, the name was correctly identified and replaced with another. The `analyzed_fields` attribute is responsible for what values are to be detected and substituted. We can add _PHONE_NUMBER_ to the list:

```python
anonymizer = PresidioAnonymizer(analyzed_fields=["PERSON", "PHONE_NUMBER"])
anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"
)
```

```text
    'My name is Wesley Flores, call me at (498)576-9526 or email me at real.slim.shady@gmail.com'
```

\
If no analyzed_fields are specified, by default the anonymizer will detect all supported formats. Below is the full list of them:

`['PERSON', 'EMAIL_ADDRESS', 'PHONE_NUMBER', 'IBAN_CODE', 'CREDIT_CARD', 'CRYPTO', 'IP_ADDRESS', 'LOCATION', 'DATE_TIME', 'NRP', 'MEDICAL_LICENSE', 'URL', 'US_BANK_NUMBER', 'US_DRIVER_LICENSE', 'US_ITIN', 'US_PASSPORT', 'US_SSN']`

**Disclaimer:** We suggest carefully defining the private data to be detected - Presidio doesn't work perfectly and it sometimes makes mistakes, so it's better to have more control over the data.

```python
anonymizer = PresidioAnonymizer()
anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"
)
```

```text
    'My name is Carla Fisher, call me at 001-683-324-0721x0644 or email me at krausejeremy@example.com'
```

\
It may be that the above list of detected fields is not sufficient. For example, the already available _PHONE_NUMBER_ field does not support polish phone numbers and confuses it with another field:

```python
anonymizer = PresidioAnonymizer()
anonymizer.anonymize("My polish phone number is 666555444")
```

```text
    'My polish phone number is QESQ21234635370499'
```

\
You can then write your own recognizers and add them to the pool of those present. How exactly to create recognizers is described in the [Presidio documentation](https://microsoft.github.io/presidio/samples/python/customizing_presidio_analyzer/).

```python
# Define the regex pattern in a Presidio `Pattern` object:
from presidio_analyzer import Pattern, PatternRecognizer

polish_phone_numbers_pattern = Pattern(
    name="polish_phone_numbers_pattern",
    regex="(?<!\w)(\(?(\+|00)?48\)?)?[ -]?\d{3}[ -]?\d{3}[ -]?\d{3}(?!\w)",
    score=1,
)

# Define the recognizer with one or more patterns
polish_phone_numbers_recognizer = PatternRecognizer(
    supported_entity="POLISH_PHONE_NUMBER", patterns=[polish_phone_numbers_pattern]
)
```

\
Now, we can add recognizer by calling `add_recognizer` method on the anonymizer:

```python
anonymizer.add_recognizer(polish_phone_numbers_recognizer)
```

\
And voil√†! With the added pattern-based recognizer, the anonymizer now handles polish phone numbers.

```python
print(anonymizer.anonymize("My polish phone number is 666555444"))
print(anonymizer.anonymize("My polish phone number is 666 555 444"))
print(anonymizer.anonymize("My polish phone number is +48 666 555 444"))
```

```text
    My polish phone number is <POLISH_PHONE_NUMBER>
    My polish phone number is <POLISH_PHONE_NUMBER>
    My polish phone number is <POLISH_PHONE_NUMBER>
```

\
The problem is - even though we recognize polish phone numbers now, we don't have a method (operator) that would tell how to substitute a given field - because of this, in the outpit we only provide string `<POLISH_PHONE_NUMBER>` We need to create a method to replace it correctly: 

```python
from faker import Faker

fake = Faker(locale="pl_PL")

def fake_polish_phone_number(_=None):
    return fake.phone_number()

fake_polish_phone_number()
```

```text
    '665 631 080'
```

\
We used Faker to create pseudo data. Now we can create an operator and add it to the anonymizer. For complete information about operators and their creation, see the Presidio documentation for [simple](https://microsoft.github.io/presidio/tutorial/10_simple_anonymization/) and [custom](https://microsoft.github.io/presidio/tutorial/11_custom_anonymization/) anonymization.

```python
from presidio_anonymizer.entities import OperatorConfig

new_operators = {
    "POLISH_PHONE_NUMBER": OperatorConfig(
        "custom", {"lambda": fake_polish_phone_number}
    )
}
```

```python
anonymizer.add_operators(new_operators)
```

```python
anonymizer.anonymize("My polish phone number is 666555444")
```

```text
    'My polish phone number is 538 521 657'
```

## Important considerations‚Äã

### Anonymizer detection rates‚Äã

**The level of anonymization and the precision of detection are just as good as the quality of the recognizers implemented.**

Texts from different sources and in different languages have varying characteristics, so it is necessary to test the detection precision and iteratively add recognizers and operators to achieve better and better results.

Microsoft Presidio gives a lot of freedom to refine anonymization. The library's author has provided his [recommendations and a step-by-step guide for improving detection rates](https://github.com/microsoft/presidio/discussions/767#discussion-3567223).

### Instance anonymization‚Äã

`PresidioAnonymizer` has no built-in memory. Therefore, two occurrences of the entity in the subsequent texts will be replaced with two different fake values:

```python
print(anonymizer.anonymize("My name is John Doe. Hi John Doe!"))
print(anonymizer.anonymize("My name is John Doe. Hi John Doe!"))
```

```text
    My name is Robert Morales. Hi Robert Morales!
    My name is Kelly Mccoy. Hi Kelly Mccoy!
```

To preserve previous anonymization results, use `PresidioReversibleAnonymizer`, which has built-in memory:

```python
from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer

anonymizer_with_memory = PresidioReversibleAnonymizer()

print(anonymizer_with_memory.anonymize("My name is John Doe. Hi John Doe!"))
print(anonymizer_with_memory.anonymize("My name is John Doe. Hi John Doe!"))
```

```text
    My name is Ashley Cervantes. Hi Ashley Cervantes!
    My name is Ashley Cervantes. Hi Ashley Cervantes!
```

You can learn more about `PresidioReversibleAnonymizer` in the next section.

- [Use case](#use-case)

- [Overview](#overview)

- [Quickstart](#quickstart)- [Using with LangChain Expression Language](#using-with-langchain-expression-language)

- [Customization](#customization)

- [Important considerations](#important-considerations)- [Anonymizer detection rates](#anonymizer-detection-rates)

- [Instance anonymization](#instance-anonymization)</doc_content>
</document>





<document index='3'>
<source>https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/qa_privacy_protection</source>
<doc_content>QA with private data protection | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# QA with private data protection

# QA with private data protection

[](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/guides/privacy/presidio_data_anonymization/qa_privacy_protection.ipynb)

In this notebook, we will look at building a basic system for question answering, based on private data. Before feeding the LLM with this data, we need to protect it so that it doesn't go to an external API (e.g. OpenAI, Anthropic). Then, after receiving the model output, we would like the data to be restored to its original form. Below you can observe an example flow of this QA system:

![](/img/qa_privacy_protection.png)In the following notebook, we will not go into the details of how the anonymizer works. If you are interested, please visit [this part of the documentation](https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/).

## Quickstart‚Äã

### Iterative process of upgrading the anonymizer‚Äã

```python
# Install necessary packages
# !pip install langchain langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker faiss-cpu tiktoken
# ! python -m spacy download en_core_web_lg
```

```python
document_content = """Date: October 19, 2021
 Witness: John Doe
 Subject: Testimony Regarding the Loss of Wallet

 Testimony Content:

 Hello Officer,

 My name is John Doe and on October 19, 2021, my wallet was stolen in the vicinity of Kilmarnock during a bike trip. This wallet contains some very important things to me.

 Firstly, the wallet contains my credit card with number 4111 1111 1111 1111, which is registered under my name and linked to my bank account, PL61109010140000071219812874.

 Additionally, the wallet had a driver's license - DL No: 999000680 issued to my name. It also houses my Social Security Number, 602-76-4532. 

 What's more, I had my polish identity card there, with the number ABC123456.

 I would like this data to be secured and protected in all possible ways. I believe It was stolen at 9:30 AM.

 In case any information arises regarding my wallet, please reach out to me on my phone number, 999-888-7777, or through my personal email, johndoe@example.com.

 Please consider this information to be highly confidential and respect my privacy. 

 The bank has been informed about the stolen credit card and necessary actions have been taken from their end. They will be reachable at their official email, support@bankname.com.
 My representative there is Victoria Cherry (her business phone: 987-654-3210).

 Thank you for your assistance,

 John Doe"""
```

```python
from langchain.schema import Document

documents = [Document(page_content=document_content)]
```

We only have one document, so before we move on to creating a QA system, let's focus on its content to begin with.

You may observe that the text contains many different PII values, some types occur repeatedly (names, phone numbers, emails), and some specific PIIs are repeated (John Doe).

```python
# Util function for coloring the PII markers
# NOTE: It will not be visible on documentation page, only in the notebook
import re

def print_colored_pii(string):
    colored_string = re.sub(
        r"(<[^>]*>)", lambda m: "\033[31m" + m.group(1) + "\033[0m", string
    )
    print(colored_string)
```

Let's proceed and try to anonymize the text with the default settings. For now, we don't replace the data with synthetic, we just mark it with markers (e.g. `<PERSON>`), so we set `add_default_faker_operators=False`:

```python
from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer

anonymizer = PresidioReversibleAnonymizer(
    add_default_faker_operators=False,
)

print_colored_pii(anonymizer.anonymize(document_content))
```

```text
    Date: <DATE_TIME>
    Witness: <PERSON>
    Subject: Testimony Regarding the Loss of Wallet
    
    Testimony Content:
    
    Hello Officer,
    
    My name is <PERSON> and on <DATE_TIME>, my wallet was stolen in the vicinity of <LOCATION> during a bike trip. This wallet contains some very important things to me.
    
    Firstly, the wallet contains my credit card with number <CREDIT_CARD>, which is registered under my name and linked to my bank account, <IBAN_CODE>.
    
    Additionally, the wallet had a driver's license - DL No: <US_DRIVER_LICENSE> issued to my name. It also houses my Social Security Number, <US_SSN>. 
    
    What's more, I had my polish identity card there, with the number ABC123456.
    
    I would like this data to be secured and protected in all possible ways. I believe It was stolen at <DATE_TIME_2>.
    
    In case any information arises regarding my wallet, please reach out to me on my phone number, <PHONE_NUMBER>, or through my personal email, <EMAIL_ADDRESS>.
    
    Please consider this information to be highly confidential and respect my privacy. 
    
    The bank has been informed about the stolen credit card and necessary actions have been taken from their end. They will be reachable at their official email, <EMAIL_ADDRESS_2>.
    My representative there is <PERSON_2> (her business phone: <UK_NHS>).
    
    Thank you for your assistance,
    
    <PERSON>
```

Let's also look at the mapping between original and anonymized values:

```python
import pprint

pprint.pprint(anonymizer.deanonymizer_mapping)
```

```text
    {'CREDIT_CARD': {'<CREDIT_CARD>': '4111 1111 1111 1111'},
     'DATE_TIME': {'<DATE_TIME>': 'October 19, 2021', '<DATE_TIME_2>': '9:30 AM'},
     'EMAIL_ADDRESS': {'<EMAIL_ADDRESS>': 'johndoe@example.com',
                       '<EMAIL_ADDRESS_2>': 'support@bankname.com'},
     'IBAN_CODE': {'<IBAN_CODE>': 'PL61109010140000071219812874'},
     'LOCATION': {'<LOCATION>': 'Kilmarnock'},
     'PERSON': {'<PERSON>': 'John Doe', '<PERSON_2>': 'Victoria Cherry'},
     'PHONE_NUMBER': {'<PHONE_NUMBER>': '999-888-7777'},
     'UK_NHS': {'<UK_NHS>': '987-654-3210'},
     'US_DRIVER_LICENSE': {'<US_DRIVER_LICENSE>': '999000680'},
     'US_SSN': {'<US_SSN>': '602-76-4532'}}
```

In general, the anonymizer works pretty well, but I can observe two things to improve here:

1. Datetime redundancy - we have two different entities recognized as `DATE_TIME`, but they contain different type of information. The first one is a date (_October 19, 2021_), the second one is a time (_9:30 AM_). We can improve this by adding a new recognizer to the anonymizer, which will treat time separately from the date.

2. Polish ID - polish ID has unique pattern, which is not by default part of anonymizer recognizers. The value _ABC123456_ is not anonymized.

The solution is simple: we need to add a new recognizers to the anonymizer. You can read more about it in [presidio documentation](https://microsoft.github.io/presidio/analyzer/adding_recognizers/).

Let's add new recognizers:

```python
# Define the regex pattern in a Presidio `Pattern` object:
from presidio_analyzer import Pattern, PatternRecognizer

polish_id_pattern = Pattern(
    name="polish_id_pattern",
    regex="[A-Z]{3}\d{6}",
    score=1,
)
time_pattern = Pattern(
    name="time_pattern",
    regex="(1[0-2]|0?[1-9]):[0-5][0-9] (AM|PM)",
    score=1,
)

# Define the recognizer with one or more patterns
polish_id_recognizer = PatternRecognizer(
    supported_entity="POLISH_ID", patterns=[polish_id_pattern]
)
time_recognizer = PatternRecognizer(supported_entity="TIME", patterns=[time_pattern])
```

And now, we're adding recognizers to our anonymizer:

```python
anonymizer.add_recognizer(polish_id_recognizer)
anonymizer.add_recognizer(time_recognizer)
```

Note that our anonymization instance remembers previously detected and anonymized values, including those that were not detected correctly (e.g., _"9:30 AM"_ taken as `DATE_TIME`). So it's worth removing this value, or resetting the entire mapping now that our recognizers have been updated:

```python
anonymizer.reset_deanonymizer_mapping()
```

Let's anonymize the text and see the results:

```python
print_colored_pii(anonymizer.anonymize(document_content))
```

```text
    Date: <DATE_TIME>
    Witness: <PERSON>
    Subject: Testimony Regarding the Loss of Wallet
    
    Testimony Content:
    
    Hello Officer,
    
    My name is <PERSON> and on <DATE_TIME>, my wallet was stolen in the vicinity of <LOCATION> during a bike trip. This wallet contains some very important things to me.
    
    Firstly, the wallet contains my credit card with number <CREDIT_CARD>, which is registered under my name and linked to my bank account, <IBAN_CODE>.
    
    Additionally, the wallet had a driver's license - DL No: <US_DRIVER_LICENSE> issued to my name. It also houses my Social Security Number, <US_SSN>. 
    
    What's more, I had my polish identity card there, with the number <POLISH_ID>.
    
    I would like this data to be secured and protected in all possible ways. I believe It was stolen at <TIME>.
    
    In case any information arises regarding my wallet, please reach out to me on my phone number, <PHONE_NUMBER>, or through my personal email, <EMAIL_ADDRESS>.
    
    Please consider this information to be highly confidential and respect my privacy. 
    
    The bank has been informed about the stolen credit card and necessary actions have been taken from their end. They will be reachable at their official email, <EMAIL_ADDRESS_2>.
    My representative there is <PERSON_2> (her business phone: <UK_NHS>).
    
    Thank you for your assistance,
    
    <PERSON>
```

```python
pprint.pprint(anonymizer.deanonymizer_mapping)
```

```text
    {'CREDIT_CARD': {'<CREDIT_CARD>': '4111 1111 1111 1111'},
     'DATE_TIME': {'<DATE_TIME>': 'October 19, 2021'},
     'EMAIL_ADDRESS': {'<EMAIL_ADDRESS>': 'johndoe@example.com',
                       '<EMAIL_ADDRESS_2>': 'support@bankname.com'},
     'IBAN_CODE': {'<IBAN_CODE>': 'PL61109010140000071219812874'},
     'LOCATION': {'<LOCATION>': 'Kilmarnock'},
     'PERSON': {'<PERSON>': 'John Doe', '<PERSON_2>': 'Victoria Cherry'},
     'PHONE_NUMBER': {'<PHONE_NUMBER>': '999-888-7777'},
     'POLISH_ID': {'<POLISH_ID>': 'ABC123456'},
     'TIME': {'<TIME>': '9:30 AM'},
     'UK_NHS': {'<UK_NHS>': '987-654-3210'},
     'US_DRIVER_LICENSE': {'<US_DRIVER_LICENSE>': '999000680'},
     'US_SSN': {'<US_SSN>': '602-76-4532'}}
```

As you can see, our new recognizers work as expected. The anonymizer has replaced the time and Polish ID entities with the `<TIME>` and `<POLISH_ID>` markers, and the deanonymizer mapping has been updated accordingly.

Now, when all PII values are detected correctly, we can proceed to the next step, which is replacing the original values with synthetic ones. To do this, we need to set `add_default_faker_operators=True` (or just remove this parameter, because it's set to `True` by default):

```python
anonymizer = PresidioReversibleAnonymizer(
    add_default_faker_operators=True,
    # Faker seed is used here to make sure the same fake data is generated for the test purposes
    # In production, it is recommended to remove the faker_seed parameter (it will default to None)
    faker_seed=42,
)

anonymizer.add_recognizer(polish_id_recognizer)
anonymizer.add_recognizer(time_recognizer)

print_colored_pii(anonymizer.anonymize(document_content))
```

```text
    Date: 1986-04-18
    Witness: Brian Cox DVM
    Subject: Testimony Regarding the Loss of Wallet
    
    Testimony Content:
    
    Hello Officer,
    
    My name is Brian Cox DVM and on 1986-04-18, my wallet was stolen in the vicinity of New Rita during a bike trip. This wallet contains some very important things to me.
    
    Firstly, the wallet contains my credit card with number 6584801845146275, which is registered under my name and linked to my bank account, GB78GSWK37672423884969.
    
    Additionally, the wallet had a driver's license - DL No: 781802744 issued to my name. It also houses my Social Security Number, 687-35-1170. 
    
    What's more, I had my polish identity card there, with the number <POLISH_ID>.
    
    I would like this data to be secured and protected in all possible ways. I believe It was stolen at <TIME>.
    
    In case any information arises regarding my wallet, please reach out to me on my phone number, 7344131647, or through my personal email, jamesmichael@example.com.
    
    Please consider this information to be highly confidential and respect my privacy. 
    
    The bank has been informed about the stolen credit card and necessary actions have been taken from their end. They will be reachable at their official email, blakeerik@example.com.
    My representative there is Cristian Santos (her business phone: 2812140441).
    
    Thank you for your assistance,
    
    Brian Cox DVM
```

As you can see, almost all values have been replaced with synthetic ones. The only exception is the Polish ID number and time, which are not supported by the default faker operators. We can add new operators to the anonymizer, which will generate random data. You can read more about custom operators [here](https://microsoft.github.io/presidio/tutorial/11_custom_anonymization/).

```python
from faker import Faker

fake = Faker()

def fake_polish_id(_=None):
    return fake.bothify(text="???######").upper()

fake_polish_id()
```

```text
    'VTC592627'
```

```python
def fake_time(_=None):
    return fake.time(pattern="%I:%M %p")

fake_time()
```

```text
    '03:14 PM'
```

Let's add newly created operators to the anonymizer:

```python
from presidio_anonymizer.entities import OperatorConfig

new_operators = {
    "POLISH_ID": OperatorConfig("custom", {"lambda": fake_polish_id}),
    "TIME": OperatorConfig("custom", {"lambda": fake_time}),
}

anonymizer.add_operators(new_operators)
```

And anonymize everything once again:

```python
anonymizer.reset_deanonymizer_mapping()
print_colored_pii(anonymizer.anonymize(document_content))
```

```text
    Date: 1974-12-26
    Witness: Jimmy Murillo
    Subject: Testimony Regarding the Loss of Wallet
    
    Testimony Content:
    
    Hello Officer,
    
    My name is Jimmy Murillo and on 1974-12-26, my wallet was stolen in the vicinity of South Dianeshire during a bike trip. This wallet contains some very important things to me.
    
    Firstly, the wallet contains my credit card with number 213108121913614, which is registered under my name and linked to my bank account, GB17DBUR01326773602606.
    
    Additionally, the wallet had a driver's license - DL No: 532311310 issued to my name. It also houses my Social Security Number, 690-84-1613. 
    
    What's more, I had my polish identity card there, with the number UFB745084.
    
    I would like this data to be secured and protected in all possible ways. I believe It was stolen at 11:54 AM.
    
    In case any information arises regarding my wallet, please reach out to me on my phone number, 876.931.1656, or through my personal email, briannasmith@example.net.
    
    Please consider this information to be highly confidential and respect my privacy. 
    
    The bank has been informed about the stolen credit card and necessary actions have been taken from their end. They will be reachable at their official email, samuel87@example.org.
    My representative there is Joshua Blair (her business phone: 3361388464).
    
    Thank you for your assistance,
    
    Jimmy Murillo
```

```python
pprint.pprint(anonymizer.deanonymizer_mapping)
```

```text
    {'CREDIT_CARD': {'213108121913614': '4111 1111 1111 1111'},
     'DATE_TIME': {'1974-12-26': 'October 19, 2021'},
     'EMAIL_ADDRESS': {'briannasmith@example.net': 'johndoe@example.com',
                       'samuel87@example.org': 'support@bankname.com'},
     'IBAN_CODE': {'GB17DBUR01326773602606': 'PL61109010140000071219812874'},
     'LOCATION': {'South Dianeshire': 'Kilmarnock'},
     'PERSON': {'Jimmy Murillo': 'John Doe', 'Joshua Blair': 'Victoria Cherry'},
     'PHONE_NUMBER': {'876.931.1656': '999-888-7777'},
     'POLISH_ID': {'UFB745084': 'ABC123456'},
     'TIME': {'11:54 AM': '9:30 AM'},
     'UK_NHS': {'3361388464': '987-654-3210'},
     'US_DRIVER_LICENSE': {'532311310': '999000680'},
     'US_SSN': {'690-84-1613': '602-76-4532'}}
```

Voil√†! Now all values are replaced with synthetic ones. Note that the deanonymizer mapping has been updated accordingly.

### Question-answering system with PII anonymization‚Äã

Now, let's wrap it up together and create full question-answering system, based on `PresidioReversibleAnonymizer` and LangChain Expression Language (LCEL).

```python
# 1. Initialize anonymizer
anonymizer = PresidioReversibleAnonymizer(
    # Faker seed is used here to make sure the same fake data is generated for the test purposes
    # In production, it is recommended to remove the faker_seed parameter (it will default to None)
    faker_seed=42,
)

anonymizer.add_recognizer(polish_id_recognizer)
anonymizer.add_recognizer(time_recognizer)

anonymizer.add_operators(new_operators)
```

```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS

# 2. Load the data: In our case data's already loaded
# 3. Anonymize the data before indexing
for doc in documents:
    doc.page_content = anonymizer.anonymize(doc.page_content)

# 4. Split the documents into chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = text_splitter.split_documents(documents)

# 5. Index the chunks (using OpenAI embeddings, because the data is already anonymized)
embeddings = OpenAIEmbeddings()
docsearch = FAISS.from_documents(chunks, embeddings)
retriever = docsearch.as_retriever()
```

```python
from operator import itemgetter

from langchain.chat_models.openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableLambda, RunnableMap, RunnablePassthrough

# 6. Create anonymizer chain
template = """Answer the question based only on the following context:
{context}

Question: {anonymized_question}
"""
prompt = ChatPromptTemplate.from_template(template)

model = ChatOpenAI(temperature=0.3)

_inputs = RunnableMap(
    question=RunnablePassthrough(),
    # It is important to remember about question anonymization
    anonymized_question=RunnableLambda(anonymizer.anonymize),
)

anonymizer_chain = (
    _inputs
    | {
        "context": itemgetter("anonymized_question") | retriever,
        "anonymized_question": itemgetter("anonymized_question"),
    }
    | prompt
    | model
    | StrOutputParser()
)
```

```python
anonymizer_chain.invoke(
    "Where did the theft of the wallet occur, at what time, and who was it stolen from?"
)
```

```text
    'The theft of the wallet occurred in the vicinity of New Rita during a bike trip. It was stolen from Brian Cox DVM. The time of the theft was 02:22 AM.'
```

```python
# 7. Add deanonymization step to the chain
chain_with_deanonymization = anonymizer_chain | RunnableLambda(anonymizer.deanonymize)

print(
    chain_with_deanonymization.invoke(
        "Where did the theft of the wallet occur, at what time, and who was it stolen from?"
    )
)
```

```text
    The theft of the wallet occurred in the vicinity of Kilmarnock during a bike trip. It was stolen from John Doe. The time of the theft was 9:30 AM.
```

```python
print(
    chain_with_deanonymization.invoke("What was the content of the wallet in detail?")
)
```

```text
    The content of the wallet included a credit card with the number 4111 1111 1111 1111, registered under the name of John Doe and linked to the bank account PL61109010140000071219812874. It also contained a driver's license with the number 999000680 issued to John Doe, as well as his Social Security Number 602-76-4532. Additionally, the wallet had a Polish identity card with the number ABC123456.
```

```python
print(chain_with_deanonymization.invoke("Whose phone number is it: 999-888-7777?"))
```

```text
    The phone number 999-888-7777 belongs to John Doe.
```

### Alternative approach: local embeddings + anonymizing the context after indexing‚Äã

If for some reason you would like to index the data in its original form, or simply use custom embeddings, below is an example of how to do it:

```python
anonymizer = PresidioReversibleAnonymizer(
    # Faker seed is used here to make sure the same fake data is generated for the test purposes
    # In production, it is recommended to remove the faker_seed parameter (it will default to None)
    faker_seed=42,
)

anonymizer.add_recognizer(polish_id_recognizer)
anonymizer.add_recognizer(time_recognizer)

anonymizer.add_operators(new_operators)
```

```python
from langchain.embeddings import HuggingFaceBgeEmbeddings

model_name = "BAAI/bge-base-en-v1.5"
# model_kwargs = {'device': 'cuda'}
encode_kwargs = {"normalize_embeddings": True}  # set True to compute cosine similarity
local_embeddings = HuggingFaceBgeEmbeddings(
    model_name=model_name,
    # model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs,
    query_instruction="Represent this sentence for searching relevant passages:",
)
```

```python
documents = [Document(page_content=document_content)]

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = text_splitter.split_documents(documents)

docsearch = FAISS.from_documents(chunks, local_embeddings)
retriever = docsearch.as_retriever()
```

```python
template = """Answer the question based only on the following context:
{context}

Question: {anonymized_question}
"""
prompt = ChatPromptTemplate.from_template(template)

model = ChatOpenAI(temperature=0.2)
```

```python
from langchain.prompts.prompt import PromptTemplate
from langchain.schema import format_document

DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template="{page_content}")

def _combine_documents(
    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator="\n\n"
):
    doc_strings = [format_document(doc, document_prompt) for doc in docs]
    return document_separator.join(doc_strings)

chain_with_deanonymization = (
    RunnableMap({"question": RunnablePassthrough()})
    | {
        "context": itemgetter("question")
        | retriever
        | _combine_documents
        | anonymizer.anonymize,
        "anonymized_question": lambda x: anonymizer.anonymize(x["question"]),
    }
    | prompt
    | model
    | StrOutputParser()
    | RunnableLambda(anonymizer.deanonymize)
)
```

```python
print(
    chain_with_deanonymization.invoke(
        "Where did the theft of the wallet occur, at what time, and who was it stolen from?"
    )
)
```

```text
    The theft of the wallet occurred in the vicinity of Kilmarnock during a bike trip. It was stolen from John Doe. The time of the theft was 9:30 AM.
```

```python
print(
    chain_with_deanonymization.invoke("What was the content of the wallet in detail?")
)
```

```text
    The content of the wallet included:
    1. Credit card number: 4111 1111 1111 1111
    2. Bank account number: PL61109010140000071219812874
    3. Driver's license number: 999000680
    4. Social Security Number: 602-76-4532
    5. Polish identity card number: ABC123456
```

```python
print(chain_with_deanonymization.invoke("Whose phone number is it: 999-888-7777?"))
```

```text
    The phone number 999-888-7777 belongs to John Doe.
```

- [Quickstart](#quickstart)- [Iterative process of upgrading the anonymizer](#iterative-process-of-upgrading-the-anonymizer)

- [Question-answering system with PII anonymization](#question-answering-system-with-pii-anonymization)

- [Alternative approach: local embeddings + anonymizing the context after indexing](#alternative-approach-local-embeddings--anonymizing-the-context-after-indexing)</doc_content>
</document>





<document index='4'>
<source>https://python.langchain.com/docs/integrations/document_loaders/email</source>
<doc_content>Email | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Email

This notebook shows how to load email (`.eml`) or `Microsoft Outlook` (`.msg`) files.

## Using Unstructured‚Äã

```python
#!pip install unstructured
```

```python
from langchain.document_loaders import UnstructuredEmailLoader
```

```python
loader = UnstructuredEmailLoader("example_data/fake-email.eml")
```

```python
data = loader.load()
```

```python
data
```

```text
    [Document(page_content='This is a test email to use for unit tests.\n\nImportant points:\n\nRoses are red\n\nViolets are blue', metadata={'source': 'example_data/fake-email.eml'})]
```

### Retain Elements‚Äã

Under the hood, Unstructured creates different "elements" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode="elements"`.

```python
loader = UnstructuredEmailLoader("example_data/fake-email.eml", mode="elements")
```

```python
data = loader.load()
```

```python
data[0]
```

```text
    Document(page_content='This is a test email to use for unit tests.', metadata={'source': 'example_data/fake-email.eml', 'filename': 'fake-email.eml', 'file_directory': 'example_data', 'date': '2022-12-16T17:04:16-05:00', 'filetype': 'message/rfc822', 'sent_from': ['Matthew Robinson <mrobinson@unstructured.io>'], 'sent_to': ['Matthew Robinson <mrobinson@unstructured.io>'], 'subject': 'Test Email', 'category': 'NarrativeText'})
```

### Processing Attachments‚Äã

You can process attachments with `UnstructuredEmailLoader` by setting `process_attachments=True` in the constructor. By default, attachments will be partitioned using the `partition` function from `unstructured`. You can use a different partitioning function by passing the function to the `attachment_partitioner` kwarg.

```python
loader = UnstructuredEmailLoader(
    "example_data/fake-email.eml",
    mode="elements",
    process_attachments=True,
)
```

```python
data = loader.load()
```

```python
data[0]
```

```text
    Document(page_content='This is a test email to use for unit tests.', metadata={'source': 'example_data/fake-email.eml', 'filename': 'fake-email.eml', 'file_directory': 'example_data', 'date': '2022-12-16T17:04:16-05:00', 'filetype': 'message/rfc822', 'sent_from': ['Matthew Robinson <mrobinson@unstructured.io>'], 'sent_to': ['Matthew Robinson <mrobinson@unstructured.io>'], 'subject': 'Test Email', 'category': 'NarrativeText'})
```

## Using OutlookMessageLoader‚Äã

```python
#!pip install extract_msg
```

```python
from langchain.document_loaders import OutlookMessageLoader
```

```python
loader = OutlookMessageLoader("example_data/fake-email.msg")
```

```python
data = loader.load()
```

```python
data[0]
```

```text
    Document(page_content='This is a test email to experiment with the MS Outlook MSG Extractor\r\n\r\n\r\n-- \r\n\r\n\r\nKind regards\r\n\r\n\r\n\r\n\r\nBrian Zhou\r\n\r\n', metadata={'subject': 'Test for TIF files', 'sender': 'Brian Zhou <brizhou@gmail.com>', 'date': 'Mon, 18 Nov 2013 16:26:24 +0800'})
```

- [Using Unstructured](#using-unstructured)- [Retain Elements](#retain-elements)

- [Processing Attachments](#processing-attachments)

- [Using OutlookMessageLoader](#using-outlookmessageloader)</doc_content>
</document>





<document index='5'>
<source>https://python.langchain.com/docs/modules/agents/agent_types/react_docstore</source>
<doc_content>ReAct document store | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# ReAct document store

This walkthrough showcases using an agent to implement the [ReAct](https://react-lm.github.io/) logic for working with document store specifically.

```python
from langchain.agents import AgentType, Tool, initialize_agent
from langchain.agents.react.base import DocstoreExplorer
from langchain.docstore import Wikipedia
from langchain.llms import OpenAI

docstore = DocstoreExplorer(Wikipedia())
tools = [
    Tool(
        name="Search",
        func=docstore.search,
        description="useful for when you need to ask with search",
    ),
    Tool(
        name="Lookup",
        func=docstore.lookup,
        description="useful for when you need to ask with lookup",
    ),
]

llm = OpenAI(temperature=0, model_name="text-davinci-002")
react = initialize_agent(tools, llm, agent=AgentType.REACT_DOCSTORE, verbose=True)
```

```python
question = "Author David Chanoff has collaborated with a U.S. Navy admiral who served as the ambassador to the United Kingdom under which President?"
react.run(question)
```

```text
    
    
    > Entering new AgentExecutor chain...
    
    Thought: I need to search David Chanoff and find the U.S. Navy admiral he collaborated with. Then I need to find which President the admiral served under.
    
    Action: Search[David Chanoff]
    
    Observation: David Chanoff is a noted author of non-fiction work. His work has typically involved collaborations with the principal protagonist of the work concerned. His collaborators have included; Augustus A. White, Joycelyn Elders, ƒêo√†n VƒÉn To·∫°i, William J. Crowe, Ariel Sharon, Kenneth Good and Felix Zandman. He has also written about a wide range of subjects including literary history, education and foreign for The Washington Post, The New Republic and The New York Times Magazine. He has published more than twelve books.
    Thought: The U.S. Navy admiral David Chanoff collaborated with is William J. Crowe. I need to find which President he served under.
    
    Action: Search[William J. Crowe]
    
    Observation: William James Crowe Jr. (January 2, 1925 ‚Äì October 18, 2007) was a United States Navy admiral and diplomat who served as the 11th chairman of the Joint Chiefs of Staff under Presidents Ronald Reagan and George H. W. Bush, and as the ambassador to the United Kingdom and Chair of the Intelligence Oversight Board under President Bill Clinton.
    Thought: William J. Crowe served as the ambassador to the United Kingdom under President Bill Clinton, so the answer is Bill Clinton.
    
    Action: Finish[Bill Clinton]
    
    > Finished chain.

    'Bill Clinton'
```</doc_content>
</document>





<document index='6'>
<source>https://python.langchain.com/docs/security</source>
<doc_content>Security | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Security

LangChain has a large ecosystem of integrations with various external resources like local and remote file systems, APIs and databases. These integrations allow developers to create versatile applications that combine the power of LLMs with the ability to access, interact with and manipulate external resources.

## Best Practices‚Äã

When building such applications developers should remember to follow good security practices:

- [Limit Permissions](https://en.wikipedia.org/wiki/Principle_of_least_privilege): Scope permissions specifically to the application's need. Granting broad or excessive permissions can introduce significant security vulnerabilities. To avoid such vulnerabilities, consider using read-only credentials, disallowing access to sensitive resources, using sandboxing techniques (such as running inside a container), etc. as appropriate for your application.

- **Anticipate Potential Misuse**: Just as humans can err, so can Large Language Models (LLMs). Always assume that any system access or credentials may be used in any way allowed by the permissions they are assigned. For example, if a pair of database credentials allows deleting data, it‚Äôs safest to assume that any LLM able to use those credentials may in fact delete data.

- [Defense in Depth](https://en.wikipedia.org/wiki/Defense_in_depth_(computing)): No security technique is perfect. Fine-tuning and good chain design can reduce, but not eliminate, the odds that a Large Language Model (LLM) may make a mistake. It‚Äôs best to combine multiple layered security approaches rather than relying on any single layer of defense to ensure security. For example: use both read-only permissions and sandboxing to ensure that LLMs are only able to access data that is explicitly meant for them to use.

Risks of not doing so include, but are not limited to:

- Data corruption or loss.

- Unauthorized access to confidential information.

- Compromised performance or availability of critical resources.

Example scenarios with mitigation strategies:

- A user may ask an agent with access to the file system to delete files that should not be deleted or read the content of files that contain sensitive information. To mitigate, limit the agent to only use a specific directory and only allow it to read or write files that are safe to read or write. Consider further sandboxing the agent by running it in a container.

- A user may ask an agent with write access to an external API to write malicious data to the API, or delete data from that API. To mitigate, give the agent read-only API keys, or limit it to only use endpoints that are already resistant to such misuse.

- A user may ask an agent with access to a database to drop a table or mutate the schema. To mitigate, scope the credentials to only the tables that the agent needs to access and consider issuing READ-ONLY credentials.

If you're building applications that access external resources like file systems, APIs
or databases, consider speaking with your company's security team to determine how to best
design and secure your applications.

## Reporting a Vulnerability‚Äã

Please report security vulnerabilities by email to [security@langchain.dev.](mailto:security@langchain.dev.) This will ensure the issue is promptly triaged and acted upon as needed.

## Enterprise solutions‚Äã

LangChain may offer enterprise solutions for customers who have additional security
requirements. Please contact us at [sales@langchain.dev](mailto:sales@langchain.dev).

- [Best Practices](#best-practices)

- [Reporting a Vulnerability](#reporting-a-vulnerability)

- [Enterprise solutions](#enterprise-solutions)</doc_content>
</document>





<document index='7'>
<source>https://python.langchain.com/docs/guides/safety/</source>
<doc_content>Safety | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Safety

One of the key concerns with using LLMs is that they may generate harmful or unethical text. This is an area of active research in the field. Here we present some built-in chains inspired by this research, which are intended to make the outputs of LLMs safer.

- [Amazon Comprehend moderation chain](/docs/guides/safety/amazon_comprehend_chain): Use [Amazon Comprehend](https://aws.amazon.com/comprehend/) to detect and handle Personally Identifiable Information (PII) and toxicity.

- [Constitutional chain](/docs/guides/safety/constitutional_chain): Prompt the model with a set of principles which should guide the model behavior.

- [Hugging Face prompt injection identification](/docs/guides/safety/huggingface_prompt_injection_identification): Detect and handle prompt injection attacks. 

- [Logical Fallacy chain](/docs/guides/safety/logical_fallacy_chain): Checks the model output against logical fallacies to correct any deviation.

- [Moderation chain](/docs/guides/safety/moderation): Check if any output text is harmful and flag it.</doc_content>
</document>





<document index='8'>
<source>https://api.python.langchain.com/en/latest/tools/langchain.tools.office365.messages_search.SearchEmailsInput.html</source>
<doc_content>langchain.tools.office365.messages_search.SearchEmailsInput ‚Äî ü¶úüîó LangChain 0.0.337

API

Experimental

Python Docs

Toggle Menu

PrevUp
Next

LangChain 0.0.337

langchain.tools.office365.messages_search.SearchEmailsInput

langchain.tools.office365.messages_search.SearchEmailsInput¬∂

class langchain.tools.office365.messages_search.SearchEmailsInput[source]¬∂
Bases: BaseModel
Input for SearchEmails Tool.
Create a new model by parsing and validating input data from keyword arguments.
Raises ValidationError if the input data cannot be parsed to form a valid model.

param folder: str = None¬∂
If the user wants to search in only one folder, the name of the folder. Default folders are ‚Äúinbox‚Äù, ‚Äúdrafts‚Äù, ‚Äúsent items‚Äù, ‚Äúdeleted ttems‚Äù, but users can search custom folders as well.

param max_results: int = 10¬∂
The maximum number of results to return.

param query: str [Required]¬∂
The Microsoift Graph v1.0 $search query. Example filters include from:sender, from:sender, to:recipient, subject:subject, recipients:list_of_recipients, body:excitement, importance:high, received>2022-12-01, received<2021-12-01, sent>2022-12-01, sent<2021-12-01, hasAttachments:true  attachment:api-catalog.md, cc:samanthab@contoso.com, bcc:samanthab@contoso.com, body:excitement date range example: received:2023-06-08..2023-06-09  matching example: from:amy OR from:david.

param truncate: bool = True¬∂
Whether the email body is truncated to meet token number limits. Set to False for searches that will retrieve very few results, otherwise, set to True

classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) ‚Üí Model¬∂
Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if Config.extra = ‚Äòallow‚Äô was set since it adds all passed values

copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) ‚Üí Model¬∂
Duplicate a model, optionally choose which fields to include, exclude and change.

Parameters

include ‚Äì fields to include in new model
exclude ‚Äì fields to exclude from new model, as with values this takes precedence over include
update ‚Äì values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data
deep ‚Äì set to True to make a deep copy of the model

Returns
new model instance

dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) ‚Üí DictStrAny¬∂
Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.

classmethod from_orm(obj: Any) ‚Üí Model¬∂

json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) ‚Üí unicode¬∂
Generate a JSON representation of the model, include and exclude arguments as per dict().
encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().

classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) ‚Üí Model¬∂

classmethod parse_obj(obj: Any) ‚Üí Model¬∂

classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) ‚Üí Model¬∂

classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') ‚Üí DictStrAny¬∂

classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) ‚Üí unicode¬∂

classmethod update_forward_refs(**localns: Any) ‚Üí None¬∂
Try to update ForwardRefs on fields based on this Model, globalns and localns.

classmethod validate(value: Any) ‚Üí Model¬∂

            ¬© 2023, Harrison Chase.
          Last updated on Nov 17, 2023.
          Show this page source</doc_content>
</document>





<document index='9'>
<source>https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/reversible</source>
<doc_content>Reversible anonymization | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Reversible anonymization

# Reversible data anonymization with Microsoft Presidio

[](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/guides/privacy/presidio_data_anonymization/reversible.ipynb)

## Use case‚Äã

We have already written about the importance of anonymizing sensitive data in the previous section. **Reversible Anonymization** is an equally essential technology while sharing information with language models, as it balances data protection with data usability. This technique involves masking sensitive personally identifiable information (PII), yet it can be reversed and original data can be restored when authorized users need it. Its main advantage lies in the fact that while it conceals individual identities to prevent misuse, it also allows the concealed data to be accurately unmasked should it be necessary for legal or compliance purposes. 

## Overview‚Äã

We implemented the `PresidioReversibleAnonymizer`, which consists of two parts:

1. anonymization - it works the same way as `PresidioAnonymizer`, plus the object itself stores a mapping of made-up values to original ones, for example:

```text
    {
        "PERSON": {
            "<anonymized>": "<original>",
            "John Doe": "Slim Shady"
        },
        "PHONE_NUMBER": {
            "111-111-1111": "555-555-5555"
        }
        ...
    }
```

1. deanonymization - using the mapping described above, it matches fake data with original data and then substitutes it.

Between anonymization and deanonymization user can perform different operations, for example, passing the output to LLM.

## Quickstart‚Äã

```python
# Install necessary packages
# ! pip install langchain langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker
# ! python -m spacy download en_core_web_lg
```

`PresidioReversibleAnonymizer` is not significantly different from its predecessor (`PresidioAnonymizer`) in terms of anonymization:

```python
from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer

anonymizer = PresidioReversibleAnonymizer(
    analyzed_fields=["PERSON", "PHONE_NUMBER", "EMAIL_ADDRESS", "CREDIT_CARD"],
    # Faker seed is used here to make sure the same fake data is generated for the test purposes
    # In production, it is recommended to remove the faker_seed parameter (it will default to None)
    faker_seed=42,
)

anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com. "
    "By the way, my card number is: 4916 0387 9536 0861"
)
```

```text
    'My name is Maria Lynch, call me at 7344131647 or email me at jamesmichael@example.com. By the way, my card number is: 4838637940262'
```

This is what the full string we want to deanonymize looks like:

```python
# We know this data, as we set the faker_seed parameter
fake_name = "Maria Lynch"
fake_phone = "7344131647"
fake_email = "jamesmichael@example.com"
fake_credit_card = "4838637940262"

anonymized_text = f"""{fake_name} recently lost his wallet. 
Inside is some cash and his credit card with the number {fake_credit_card}. 
If you would find it, please call at {fake_phone} or write an email here: {fake_email}.
{fake_name} would be very grateful!"""

print(anonymized_text)
```

```text
    Maria Lynch recently lost his wallet. 
    Inside is some cash and his credit card with the number 4838637940262. 
    If you would find it, please call at 7344131647 or write an email here: jamesmichael@example.com.
    Maria Lynch would be very grateful!
```

And now, using the `deanonymize` method, we can reverse the process:

```python
print(anonymizer.deanonymize(anonymized_text))
```

```text
    Slim Shady recently lost his wallet. 
    Inside is some cash and his credit card with the number 4916 0387 9536 0861. 
    If you would find it, please call at 313-666-7440 or write an email here: real.slim.shady@gmail.com.
    Slim Shady would be very grateful!
```

### Using with LangChain Expression Language‚Äã

With LCEL we can easily chain together anonymization and deanonymization with the rest of our application. This is an example of using the anonymization mechanism with a query to LLM (without deanonymization for now):

```python
text = """Slim Shady recently lost his wallet. 
Inside is some cash and his credit card with the number 4916 0387 9536 0861. 
If you would find it, please call at 313-666-7440 or write an email here: real.slim.shady@gmail.com."""
```

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts.prompt import PromptTemplate

anonymizer = PresidioReversibleAnonymizer()

template = """Rewrite this text into an official, short email:

{anonymized_text}"""
prompt = PromptTemplate.from_template(template)
llm = ChatOpenAI(temperature=0)

chain = {"anonymized_text": anonymizer.anonymize} | prompt | llm
response = chain.invoke(text)
print(response.content)
```

```text
    Dear Sir/Madam,
    
    We regret to inform you that Monique Turner has recently misplaced his wallet, which contains a sum of cash and his credit card with the number 213152056829866. 
    
    If you happen to come across this wallet, kindly contact us at (770)908-7734x2835 or send an email to barbara25@example.net.
    
    Thank you for your cooperation.
    
    Sincerely,
    [Your Name]
```

Now, let's add **deanonymization step** to our sequence:

```python
chain = chain | (lambda ai_message: anonymizer.deanonymize(ai_message.content))
response = chain.invoke(text)
print(response)
```

```text
    Dear Sir/Madam,
    
    We regret to inform you that Slim Shady has recently misplaced his wallet, which contains a sum of cash and his credit card with the number 4916 0387 9536 0861. 
    
    If you happen to come across this wallet, kindly contact us at 313-666-7440 or send an email to real.slim.shady@gmail.com.
    
    Thank you for your cooperation.
    
    Sincerely,
    [Your Name]
```

Anonymized data was given to the model itself, and therefore it was protected from being leaked to the outside world. Then, the model's response was processed, and the factual value was replaced with the real one.

## Extra knowledge‚Äã

`PresidioReversibleAnonymizer` stores the mapping of the fake values to the original values in the `deanonymizer_mapping` parameter, where key is fake PII and value is the original one: 

```python
from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer

anonymizer = PresidioReversibleAnonymizer(
    analyzed_fields=["PERSON", "PHONE_NUMBER", "EMAIL_ADDRESS", "CREDIT_CARD"],
    # Faker seed is used here to make sure the same fake data is generated for the test purposes
    # In production, it is recommended to remove the faker_seed parameter (it will default to None)
    faker_seed=42,
)

anonymizer.anonymize(
    "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com. "
    "By the way, my card number is: 4916 0387 9536 0861"
)

anonymizer.deanonymizer_mapping
```

```text
    {'PERSON': {'Maria Lynch': 'Slim Shady'},
     'PHONE_NUMBER': {'7344131647': '313-666-7440'},
     'EMAIL_ADDRESS': {'jamesmichael@example.com': 'real.slim.shady@gmail.com'},
     'CREDIT_CARD': {'4838637940262': '4916 0387 9536 0861'}}
```

Anonymizing more texts will result in new mapping entries:

```python
print(
    anonymizer.anonymize(
        "Do you have his VISA card number? Yep, it's 4001 9192 5753 7193. I'm John Doe by the way."
    )
)

anonymizer.deanonymizer_mapping
```

```text
    Do you have his VISA card number? Yep, it's 3537672423884966. I'm William Bowman by the way.

    {'PERSON': {'Maria Lynch': 'Slim Shady', 'William Bowman': 'John Doe'},
     'PHONE_NUMBER': {'7344131647': '313-666-7440'},
     'EMAIL_ADDRESS': {'jamesmichael@example.com': 'real.slim.shady@gmail.com'},
     'CREDIT_CARD': {'4838637940262': '4916 0387 9536 0861',
      '3537672423884966': '4001 9192 5753 7193'}}
```

Thanks to the built-in memory, entities that have already been detected and anonymised will take the same form in subsequent processed texts, so no duplicates will exist in the mapping:

```python
print(
    anonymizer.anonymize(
        "My VISA card number is 4001 9192 5753 7193 and my name is John Doe."
    )
)

anonymizer.deanonymizer_mapping
```

```text
    My VISA card number is 3537672423884966 and my name is William Bowman.

    {'PERSON': {'Maria Lynch': 'Slim Shady', 'William Bowman': 'John Doe'},
     'PHONE_NUMBER': {'7344131647': '313-666-7440'},
     'EMAIL_ADDRESS': {'jamesmichael@example.com': 'real.slim.shady@gmail.com'},
     'CREDIT_CARD': {'4838637940262': '4916 0387 9536 0861',
      '3537672423884966': '4001 9192 5753 7193'}}
```

We can save the mapping itself to a file for future use: 

```python
# We can save the deanonymizer mapping as a JSON or YAML file

anonymizer.save_deanonymizer_mapping("deanonymizer_mapping.json")
# anonymizer.save_deanonymizer_mapping("deanonymizer_mapping.yaml")
```

And then, load it in another `PresidioReversibleAnonymizer` instance:

```python
anonymizer = PresidioReversibleAnonymizer()

anonymizer.deanonymizer_mapping
```

```text
    {}
```

```python
anonymizer.load_deanonymizer_mapping("deanonymizer_mapping.json")

anonymizer.deanonymizer_mapping
```

```text
    {'PERSON': {'Maria Lynch': 'Slim Shady', 'William Bowman': 'John Doe'},
     'PHONE_NUMBER': {'7344131647': '313-666-7440'},
     'EMAIL_ADDRESS': {'jamesmichael@example.com': 'real.slim.shady@gmail.com'},
     'CREDIT_CARD': {'4838637940262': '4916 0387 9536 0861',
      '3537672423884966': '4001 9192 5753 7193'}}
```

### Custom deanonymization strategy‚Äã

The default deanonymization strategy is to exactly match the substring in the text with the mapping entry. Due to the indeterminism of LLMs, it may be that the model will change the format of the private data slightly or make a typo, for example:

- _Keanu Reeves_ -> _Kaenu Reeves_

- _John F. Kennedy_ -> _John Kennedy_

- _Main St, New York_ -> _New York_

It is therefore worth considering appropriate prompt engineering (have the model return PII in unchanged format) or trying to implement your replacing strategy. For example, you can use fuzzy matching - this will solve problems with typos and minor changes in the text. Some implementations of the swapping strategy can be found in the file `deanonymizer_matching_strategies.py`.

```python
from langchain_experimental.data_anonymizer.deanonymizer_matching_strategies import (
    case_insensitive_matching_strategy,
)

# Original name: Maria Lynch
print(anonymizer.deanonymize("maria lynch"))
print(
    anonymizer.deanonymize(
        "maria lynch", deanonymizer_matching_strategy=case_insensitive_matching_strategy
    )
)
```

```text
    maria lynch
    Slim Shady
```

```python
from langchain_experimental.data_anonymizer.deanonymizer_matching_strategies import (
    fuzzy_matching_strategy,
)

# Original name: Maria Lynch
# Original phone number: 7344131647 (without dashes)
print(anonymizer.deanonymize("Call Maria K. Lynch at 734-413-1647"))
print(
    anonymizer.deanonymize(
        "Call Maria K. Lynch at 734-413-1647",
        deanonymizer_matching_strategy=fuzzy_matching_strategy,
    )
)
```

```text
    Call Maria K. Lynch at 734-413-1647
    Call Slim Shady at 313-666-7440
```

It seems that the combined method works best:

- first apply the exact match strategy

- then match the rest using the fuzzy strategy

```python
from langchain_experimental.data_anonymizer.deanonymizer_matching_strategies import (
    combined_exact_fuzzy_matching_strategy,
)

# Changed some values for fuzzy match showcase:
# - "Maria Lynch" -> "Maria K. Lynch"
# - "7344131647" -> "734-413-1647"
# - "213186379402654" -> "2131 8637 9402 654"
print(
    anonymizer.deanonymize(
        (
            "Are you Maria F. Lynch? I found your card with number 4838 6379 40262.\n"
            "Is this your phone number: 734-413-1647?\n"
            "Is this your email address: wdavis@example.net"
        ),
        deanonymizer_matching_strategy=combined_exact_fuzzy_matching_strategy,
    )
)
```

```text
    Are you Slim Shady? I found your card with number 4916 0387 9536 0861.
    Is this your phone number: 313-666-7440?
    Is this your email address: wdavis@example.net
```

Of course, there is no perfect method and it is worth experimenting and finding the one best suited to your use case.

## Future works‚Äã

- **better matching and substitution of fake values for real ones** - currently the strategy is based on matching full strings and then substituting them. Due to the indeterminism of language models, it may happen that the value in the answer is slightly changed (e.g. _John Doe_ -> _John_ or _Main St, New York_ -> _New York_) and such a substitution is then no longer possible. Therefore, it is worth adjusting the matching for your needs.

- [Use case](#use-case)

- [Overview](#overview)

- [Quickstart](#quickstart)- [Using with LangChain Expression Language](#using-with-langchain-expression-language)

- [Extra knowledge](#extra-knowledge)- [Custom deanonymization strategy](#custom-deanonymization-strategy)

- [Future works](#future-works)</doc_content>
</document>





<document index='10'>
<source>https://python.langchain.com/docs/integrations/document_transformers/doctran_interrogate_document</source>
<doc_content>Doctran: interrogate documents | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Doctran: interrogate documents

Documents used in a vector store knowledge base are typically stored in a narrative or conversational format. However, most user queries are in question format. If we **convert documents into Q&A format** before vectorizing them, we can increase the likelihood of retrieving relevant documents, and decrease the likelihood of retrieving irrelevant documents.

We can accomplish this using the [Doctran](https://github.com/psychic-api/doctran) library, which uses OpenAI's function calling feature to "interrogate" documents.

See [this notebook](https://github.com/psychic-api/doctran/blob/main/benchmark.ipynb) for benchmarks on vector similarity scores for various queries based on raw documents versus interrogated documents.

```bash
pip install doctran
```

```python
import json

from langchain.document_transformers import DoctranQATransformer
from langchain.schema import Document
```

```python
from dotenv import load_dotenv

load_dotenv()
```

```text
    True
```

## Input‚Äã

This is the document we'll interrogate

```python
sample_text = """[Generated with ChatGPT]

Confidential Document - For Internal Use Only

Date: July 1, 2023

Subject: Updates and Discussions on Various Topics

Dear Team,

I hope this email finds you well. In this document, I would like to provide you with some important updates and discuss various topics that require our attention. Please treat the information contained herein as highly confidential.

Security and Privacy Measures
As part of our ongoing commitment to ensure the security and privacy of our customers' data, we have implemented robust measures across all our systems. We would like to commend John Doe (email: john.doe@example.com) from the IT department for his diligent work in enhancing our network security. Moving forward, we kindly remind everyone to strictly adhere to our data protection policies and guidelines. Additionally, if you come across any potential security risks or incidents, please report them immediately to our dedicated team at security@example.com.

HR Updates and Employee Benefits
Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049-45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492-3850, email: michael.johnson@example.com).

Marketing Initiatives and Campaigns
Our marketing team has been actively working on developing new strategies to increase brand awareness and drive customer engagement. We would like to thank Sarah Thompson (phone: 415-555-1234) for her exceptional efforts in managing our social media platforms. Sarah has successfully increased our follower base by 20% in the past month alone. Moreover, please mark your calendars for the upcoming product launch event on July 15th. We encourage all team members to attend and support this exciting milestone for our company.

Research and Development Projects
In our pursuit of innovation, our research and development department has been working tirelessly on various projects. I would like to acknowledge the exceptional work of David Rodriguez (email: david.rodriguez@example.com) in his role as project lead. David's contributions to the development of our cutting-edge technology have been instrumental. Furthermore, we would like to remind everyone to share their ideas and suggestions for potential new projects during our monthly R&D brainstorming session, scheduled for July 10th.

Please treat the information in this document with utmost confidentiality and ensure that it is not shared with unauthorized individuals. If you have any questions or concerns regarding the topics discussed, please do not hesitate to reach out to me directly.

Thank you for your attention, and let's continue to work together to achieve our goals.

Best regards,

Jason Fan
Cofounder & CEO
Psychic
jason@psychic.dev
"""
print(sample_text)
```

```text
    [Generated with ChatGPT]
    
    Confidential Document - For Internal Use Only
    
    Date: July 1, 2023
    
    Subject: Updates and Discussions on Various Topics
    
    Dear Team,
    
    I hope this email finds you well. In this document, I would like to provide you with some important updates and discuss various topics that require our attention. Please treat the information contained herein as highly confidential.
    
    Security and Privacy Measures
    As part of our ongoing commitment to ensure the security and privacy of our customers' data, we have implemented robust measures across all our systems. We would like to commend John Doe (email: john.doe@example.com) from the IT department for his diligent work in enhancing our network security. Moving forward, we kindly remind everyone to strictly adhere to our data protection policies and guidelines. Additionally, if you come across any potential security risks or incidents, please report them immediately to our dedicated team at security@example.com.
    
    HR Updates and Employee Benefits
    Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049-45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492-3850, email: michael.johnson@example.com).
    
    Marketing Initiatives and Campaigns
    Our marketing team has been actively working on developing new strategies to increase brand awareness and drive customer engagement. We would like to thank Sarah Thompson (phone: 415-555-1234) for her exceptional efforts in managing our social media platforms. Sarah has successfully increased our follower base by 20% in the past month alone. Moreover, please mark your calendars for the upcoming product launch event on July 15th. We encourage all team members to attend and support this exciting milestone for our company.
    
    Research and Development Projects
    In our pursuit of innovation, our research and development department has been working tirelessly on various projects. I would like to acknowledge the exceptional work of David Rodriguez (email: david.rodriguez@example.com) in his role as project lead. David's contributions to the development of our cutting-edge technology have been instrumental. Furthermore, we would like to remind everyone to share their ideas and suggestions for potential new projects during our monthly R&D brainstorming session, scheduled for July 10th.
    
    Please treat the information in this document with utmost confidentiality and ensure that it is not shared with unauthorized individuals. If you have any questions or concerns regarding the topics discussed, please do not hesitate to reach out to me directly.
    
    Thank you for your attention, and let's continue to work together to achieve our goals.
    
    Best regards,
    
    Jason Fan
    Cofounder & CEO
    Psychic
    jason@psychic.dev
    
```

```python
documents = [Document(page_content=sample_text)]
qa_transformer = DoctranQATransformer()
transformed_document = await qa_transformer.atransform_documents(documents)
```

## Output‚Äã

After interrogating a document, the result will be returned as a new document with questions and answers provided in the metadata.

```python
transformed_document = await qa_transformer.atransform_documents(documents)
print(json.dumps(transformed_document[0].metadata, indent=2))
```

```text
    {
      "questions_and_answers": [
        {
          "question": "What is the purpose of this document?",
          "answer": "The purpose of this document is to provide important updates and discuss various topics that require the team's attention."
        },
        {
          "question": "Who is responsible for enhancing the network security?",
          "answer": "John Doe from the IT department is responsible for enhancing the network security."
        },
        {
          "question": "Where should potential security risks or incidents be reported?",
          "answer": "Potential security risks or incidents should be reported to the dedicated team at security@example.com."
        },
        {
          "question": "Who has been recognized for outstanding performance in customer service?",
          "answer": "Jane Smith has been recognized for her outstanding performance in customer service."
        },
        {
          "question": "When is the open enrollment period for the employee benefits program?",
          "answer": "The document does not specify the exact dates for the open enrollment period for the employee benefits program, but it mentions that it is fast approaching."
        },
        {
          "question": "Who should be contacted for questions or assistance regarding the employee benefits program?",
          "answer": "For questions or assistance regarding the employee benefits program, the HR representative, Michael Johnson, should be contacted."
        },
        {
          "question": "Who has been acknowledged for managing the company's social media platforms?",
          "answer": "Sarah Thompson has been acknowledged for managing the company's social media platforms."
        },
        {
          "question": "When is the upcoming product launch event?",
          "answer": "The upcoming product launch event is on July 15th."
        },
        {
          "question": "Who has been recognized for their contributions to the development of the company's technology?",
          "answer": "David Rodriguez has been recognized for his contributions to the development of the company's technology."
        },
        {
          "question": "When is the monthly R&D brainstorming session?",
          "answer": "The monthly R&D brainstorming session is scheduled for July 10th."
        },
        {
          "question": "Who should be contacted for questions or concerns regarding the topics discussed in the document?",
          "answer": "For questions or concerns regarding the topics discussed in the document, Jason Fan, the Cofounder & CEO, should be contacted."
        }
      ]
    }
```

- [Input](#input)

- [Output](#output)</doc_content>
</document>





<document index='11'>
<source>https://api.python.langchain.com/en/latest/tools/langchain.tools.gmail.utils.get_gmail_credentials.html</source>
<doc_content>langchain.tools.gmail.utils.get_gmail_credentials ‚Äî ü¶úüîó LangChain 0.0.337

API

Experimental

Python Docs

Toggle Menu

PrevUp
Next

LangChain 0.0.337

langchain.tools.gmail.utils.get_gmail_credentials

langchain.tools.gmail.utils.get_gmail_credentials¬∂

langchain.tools.gmail.utils.get_gmail_credentials(token_file: Optional[str] = None, client_secrets_file: Optional[str] = None, scopes: Optional[List[str]] = None) ‚Üí Credentials[source]¬∂
Get credentials.

Examples using get_gmail_credentials¬∂

Gmail

            ¬© 2023, Harrison Chase.
          Last updated on Nov 17, 2023.
          Show this page source</doc_content>
</document>





<document index='12'>
<source>https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.college_confidential.CollegeConfidentialLoader.html</source>
<doc_content>langchain.document_loaders.college_confidential.CollegeConfidentialLoader ‚Äî ü¶úüîó LangChain 0.0.337

API

Experimental

Python Docs

Toggle Menu

PrevUp
Next

LangChain 0.0.337

langchain.document_loaders.college_confidential.CollegeConfidentialLoader

langchain.document_loaders.college_confidential.CollegeConfidentialLoader¬∂

class langchain.document_loaders.college_confidential.CollegeConfidentialLoader(web_path: Union[str, Sequence[str]] = '', header_template: Optional[dict] = None, verify_ssl: bool = True, proxies: Optional[dict] = None, continue_on_failure: bool = False, autoset_encoding: bool = True, encoding: Optional[str] = None, web_paths: Sequence[str] = (), requests_per_second: int = 2, default_parser: str = 'html.parser', requests_kwargs: Optional[Dict[str, Any]] = None, raise_for_status: bool = False, bs_get_text_kwargs: Optional[Dict[str, Any]] = None, bs_kwargs: Optional[Dict[str, Any]] = None, session: Any = None)[source]¬∂
Load College Confidential webpages.
Initialize loader.

Parameters

web_paths ‚Äì Web paths to load from.
requests_per_second ‚Äì Max number of concurrent requests to make.
default_parser ‚Äì Default parser to use for BeautifulSoup.
requests_kwargs ‚Äì kwargs for requests
raise_for_status ‚Äì Raise an exception if http status code denotes an error.
bs_get_text_kwargs ‚Äì kwargs for beatifulsoup4 get_text
bs_kwargs ‚Äì kwargs for beatifulsoup4 web page parsing

Attributes

web_path

Methods

__init__([web_path,¬†header_template,¬†...])
Initialize loader.

aload()
Load text from the urls in web_path async into Documents.

fetch_all(urls)
Fetch all urls concurrently with rate limiting.

lazy_load()
Lazy load text from the url(s) in web_path.

load()
Load webpages as Documents.

load_and_split([text_splitter])
Load Documents and split into chunks.

scrape([parser])
Scrape data from webpage and return it in BeautifulSoup format.

scrape_all(urls[,¬†parser])
Fetch all urls, then return soups for all results.

__init__(web_path: Union[str, Sequence[str]] = '', header_template: Optional[dict] = None, verify_ssl: bool = True, proxies: Optional[dict] = None, continue_on_failure: bool = False, autoset_encoding: bool = True, encoding: Optional[str] = None, web_paths: Sequence[str] = (), requests_per_second: int = 2, default_parser: str = 'html.parser', requests_kwargs: Optional[Dict[str, Any]] = None, raise_for_status: bool = False, bs_get_text_kwargs: Optional[Dict[str, Any]] = None, bs_kwargs: Optional[Dict[str, Any]] = None, session: Any = None) ‚Üí None¬∂
Initialize loader.

Parameters

web_paths ‚Äì Web paths to load from.
requests_per_second ‚Äì Max number of concurrent requests to make.
default_parser ‚Äì Default parser to use for BeautifulSoup.
requests_kwargs ‚Äì kwargs for requests
raise_for_status ‚Äì Raise an exception if http status code denotes an error.
bs_get_text_kwargs ‚Äì kwargs for beatifulsoup4 get_text
bs_kwargs ‚Äì kwargs for beatifulsoup4 web page parsing

aload() ‚Üí List[Document]¬∂
Load text from the urls in web_path async into Documents.

async fetch_all(urls: List[str]) ‚Üí Any¬∂
Fetch all urls concurrently with rate limiting.

lazy_load() ‚Üí Iterator[Document]¬∂
Lazy load text from the url(s) in web_path.

load() ‚Üí List[Document][source]¬∂
Load webpages as Documents.

load_and_split(text_splitter: Optional[TextSplitter] = None) ‚Üí List[Document]¬∂
Load Documents and split into chunks. Chunks are returned as Documents.

Parameters
text_splitter ‚Äì TextSplitter instance to use for splitting documents.
Defaults to RecursiveCharacterTextSplitter.

Returns
List of Documents.

scrape(parser: Optional[str] = None) ‚Üí Any¬∂
Scrape data from webpage and return it in BeautifulSoup format.

scrape_all(urls: List[str], parser: Optional[str] = None) ‚Üí List[Any]¬∂
Fetch all urls, then return soups for all results.

Examples using CollegeConfidentialLoader¬∂

College Confidential

            ¬© 2023, Harrison Chase.
          Last updated on Nov 17, 2023.
          Show this page source</doc_content>
</document>





<document index='13'>
<source>https://python.langchain.com/docs/integrations/callbacks/trubrics</source>
<doc_content>Trubrics | ü¶úÔ∏èüîó Langchain

[Skip to main content](#docusaurus_skipToContent_fallback)# Trubrics

![Trubrics](https://miro.medium.com/v2/resize:fit:720/format:webp/1*AhYbKO-v8F4u3hx2aDIqKg.png)

[Trubrics](https://trubrics.com) is an LLM user analytics platform that lets you collect, analyse and manage user
prompts & feedback on AI models. In this guide we will go over how to setup the `TrubricsCallbackHandler`. 

Check out [our repo](https://github.com/trubrics/trubrics-sdk) for more information on Trubrics.

## Installation and Setup‚Äã

```bash
pip install trubrics
```

### Getting Trubrics Credentials‚Äã

If you do not have a Trubrics account, create one on [here](https://trubrics.streamlit.app/). In this tutorial, we will use the `default` project that is built upon account creation.

Now set your credentials as environment variables:

```python
import os

os.environ["TRUBRICS_EMAIL"] = "***@***"
os.environ["TRUBRICS_PASSWORD"] = "***"
```

### Usage‚Äã

The `TrubricsCallbackHandler` can receive various optional arguments. See [here](https://trubrics.github.io/trubrics-sdk/platform/user_prompts/#saving-prompts-to-trubrics) for kwargs that can be passed to Trubrics prompts.

```python
class TrubricsCallbackHandler(BaseCallbackHandler):

    """
    Callback handler for Trubrics.
    
    Args:
        project: a trubrics project, default project is "default"
        email: a trubrics account email, can equally be set in env variables
        password: a trubrics account password, can equally be set in env variables
        **kwargs: all other kwargs are parsed and set to trubrics prompt variables, or added to the `metadata` dict
    """
```

## Examples‚Äã

Here are two examples of how to use the `TrubricsCallbackHandler` with Langchain [LLMs](https://python.langchain.com/docs/modules/model_io/llms/) or [Chat Models](https://python.langchain.com/docs/modules/model_io/chat/). We will use OpenAI models, so set your `OPENAI_API_KEY` key here:

```python
os.environ["OPENAI_API_KEY"] = "sk-***"
```

### 1. With an LLM‚Äã

```python
from langchain.callbacks import TrubricsCallbackHandler
from langchain.llms import OpenAI
```

```python
llm = OpenAI(callbacks=[TrubricsCallbackHandler()])
```

```text
    [32m2023-09-26 11:30:02.149[0m | [1mINFO    [0m | [36mtrubrics.platform.auth[0m:[36mget_trubrics_auth_token[0m:[36m61[0m - [1mUser jeff.kayne@trubrics.com has been authenticated.[0m
```

```python
res = llm.generate(["Tell me a joke", "Write me a poem"])
```

```text
    [32m2023-09-26 11:30:07.760[0m | [1mINFO    [0m | [36mtrubrics.platform[0m:[36mlog_prompt[0m:[36m102[0m - [1mUser prompt saved to Trubrics.[0m
    [32m2023-09-26 11:30:08.042[0m | [1mINFO    [0m | [36mtrubrics.platform[0m:[36mlog_prompt[0m:[36m102[0m - [1mUser prompt saved to Trubrics.[0m
```

```python
print("--> GPT's joke: ", res.generations[0][0].text)
print()
print("--> GPT's poem: ", res.generations[1][0].text)
```

```text
    --> GPT's joke:  
    
    Q: What did the fish say when it hit the wall?
    A: Dam!
    
    --> GPT's poem:  
    
    A Poem of Reflection
    
    I stand here in the night,
    The stars above me filling my sight.
    I feel such a deep connection,
    To the world and all its perfection.
    
    A moment of clarity,
    The calmness in the air so serene.
    My mind is filled with peace,
    And I am released.
    
    The past and the present,
    My thoughts create a pleasant sentiment.
    My heart is full of joy,
    My soul soars like a toy.
    
    I reflect on my life,
    And the choices I have made.
    My struggles and my strife,
    The lessons I have paid.
    
    The future is a mystery,
    But I am ready to take the leap.
    I am ready to take the lead,
    And to create my own destiny.
```

### 2. With a chat model‚Äã

```python
from langchain.callbacks import TrubricsCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
```

```python
chat_llm = ChatOpenAI(
    callbacks=[
        TrubricsCallbackHandler(
            project="default",
            tags=["chat model"],
            user_id="user-id-1234",
            some_metadata={"hello": [1, 2]},
        )
    ]
)
```

```python
chat_res = chat_llm(
    [
        SystemMessage(content="Every answer of yours must be about OpenAI."),
        HumanMessage(content="Tell me a joke"),
    ]
)
```

```text
    [32m2023-09-26 11:30:10.550[0m | [1mINFO    [0m | [36mtrubrics.platform[0m:[36mlog_prompt[0m:[36m102[0m - [1mUser prompt saved to Trubrics.[0m
```

```python
print(chat_res.content)
```

```text
    Why did the OpenAI computer go to the party?
    
    Because it wanted to meet its AI friends and have a byte of fun!
```

- [Installation and Setup](#installation-and-setup)- [Getting Trubrics Credentials](#getting-trubrics-credentials)

- [Usage](#usage)

- [Examples](#examples)- [1. With an LLM](#1-with-an-llm)

- [2. With a chat model](#2-with-a-chat-model)</doc_content>
</document>





<document index='14'>
<source>https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.gmail.toolkit.GmailToolkit.html</source>
<doc_content>langchain.agents.agent_toolkits.gmail.toolkit.GmailToolkit ‚Äî ü¶úüîó LangChain 0.0.337

API

Experimental

Python Docs

Toggle Menu

PrevUp
Next

LangChain 0.0.337

langchain.agents.agent_toolkits.gmail.toolkit.GmailToolkit

langchain.agents.agent_toolkits.gmail.toolkit.GmailToolkit¬∂

class langchain.agents.agent_toolkits.gmail.toolkit.GmailToolkit[source]¬∂
Bases: BaseToolkit
Toolkit for interacting with Gmail.

Security Note: This toolkit contains tools that can read and modifythe state of a service; e.g., by reading, creating, updating, deleting
data associated with this service.
For example, this toolkit can be used to send emails on behalf of the
associated account.
See https://python.langchain.com/docs/security for more information.

Create a new model by parsing and validating input data from keyword arguments.
Raises ValidationError if the input data cannot be parsed to form a valid model.

param api_resource: Resource [Optional]¬∂

classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) ‚Üí Model¬∂
Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if Config.extra = ‚Äòallow‚Äô was set since it adds all passed values

copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) ‚Üí Model¬∂
Duplicate a model, optionally choose which fields to include, exclude and change.

Parameters

include ‚Äì fields to include in new model
exclude ‚Äì fields to exclude from new model, as with values this takes precedence over include
update ‚Äì values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data
deep ‚Äì set to True to make a deep copy of the model

Returns
new model instance

dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) ‚Üí DictStrAny¬∂
Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.

classmethod from_orm(obj: Any) ‚Üí Model¬∂

get_tools() ‚Üí List[BaseTool][source]¬∂
Get the tools in the toolkit.

json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) ‚Üí unicode¬∂
Generate a JSON representation of the model, include and exclude arguments as per dict().
encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().

classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) ‚Üí Model¬∂

classmethod parse_obj(obj: Any) ‚Üí Model¬∂

classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) ‚Üí Model¬∂

classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') ‚Üí DictStrAny¬∂

classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) ‚Üí unicode¬∂

classmethod update_forward_refs(**localns: Any) ‚Üí None¬∂
Try to update ForwardRefs on fields based on this Model, globalns and localns.

classmethod validate(value: Any) ‚Üí Model¬∂

Examples using GmailToolkit¬∂

Gmail

            ¬© 2023, Harrison Chase.
          Last updated on Nov 17, 2023.
          Show this page source</doc_content>
</document>





</documents>



Answer: There is no information about emailing for filing CVEs in the provided documents. The documents are related to LangChain and its toolkits, specifically GmailToolkit. If you need help with filing CVEs, I suggest searching for relevant resources or contacting a LangChain support team.